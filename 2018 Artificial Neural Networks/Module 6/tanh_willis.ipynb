{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Three Layer Artificial Neural Network for Pattern Data Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, yhat):\n",
    "    yloss = -1 * (((1-y) * np.log(1-yhat)) + (y * np.log(yhat)))\n",
    "    return yloss   \n",
    "\n",
    "def cost(Y, Yhat):\n",
    "    Jcost = np.sum(loss(Y, Yhat))/Y.shape[0]\n",
    "    return Jcost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_activation(yhat):    \n",
    "    return yhat\n",
    "unit_activation = np.vectorize(unit_activation)\n",
    "\n",
    "def sigmoid_activation(yhat):    \n",
    "    return 1/(1+np.exp(-yhat))\n",
    "sigmoid_activation = np.vectorize(sigmoid_activation)\n",
    "\n",
    "def relu_activation(yhat):    \n",
    "    return yhat * (yhat > 0)\n",
    "relu_activation = np.vectorize(relu_activation)\n",
    "\n",
    "def tanh_activation(yhat):\n",
    "    return (np.exp(yhat)-np.exp(-yhat))/(np.exp(yhat)+np.exp(-yhat))\n",
    "tanh_activation = np.vectorize(tanh_activation)\n",
    "\n",
    "def tanh_derivative(tanh):\n",
    "    return 1-np.square(tanh)\n",
    "tanh_derivative = np.vectorize(tanh_derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Matrices for Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features:  2\n",
      "Number of Training Examples:  320\n",
      "Number of Test Examples:  80\n"
     ]
    }
   ],
   "source": [
    "X = np.genfromtxt('pattern_rand.csv',delimiter=',', skip_header=True)[0:320,0:2].T \n",
    "Y = np.genfromtxt('pattern_rand.csv',delimiter=',', skip_header=True)[0:320,2:3].T \n",
    "\n",
    "Xt = np.genfromtxt('pattern_rand.csv',delimiter=',', skip_header=True)[320:400,0:2].T \n",
    "Yt = np.genfromtxt('pattern_rand.csv',delimiter=',', skip_header=True)[320:400,2:3].T \n",
    "Yb = np.genfromtxt('pattern_rand.csv',delimiter=',', skip_header=True)[:,2:3].T \n",
    "    \n",
    "n = X.shape[0]\n",
    "m = X.shape[1]\n",
    "t = Xt.shape[1]\n",
    "\n",
    "print(\"Number of Features: \", n)\n",
    "print(\"Number of Training Examples: \", m)\n",
    "print(\"Number of Test Examples: \", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Running Forward Propagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterations\n",
    "h = 1000\n",
    "alpha = 0.05\n",
    "\n",
    "# Initialization of J and Yhat\n",
    "J = np.zeros((1,h))\n",
    "cost_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# IL0: Number of inputs to Layer 0\n",
    "# NL0: Number of neurons in Layer 0\n",
    "IL0 = n\n",
    "NL0 = n\n",
    "# The first layer is input layer so both number of inputs \n",
    "# and number of neurons are equal to number of features\n",
    "\n",
    "# IL1: Number of inputs to Layer 1\n",
    "# NL1: Number of neurons in Layer 1\n",
    "IL1 = NL0\n",
    "NL1 = 4\n",
    "# As there are n neurons in the previous layer, the number\n",
    "# of inputs to Layer 1 is equal to n. Number of neurons\n",
    "# may be any. \n",
    "\n",
    "# IL2: Number of inputs to Layer 2\n",
    "# NL2: Number of neurons in Layer 2\n",
    "IL2 = NL1\n",
    "NL2 = 1\n",
    "# Number of inputs in Layer 2 equals to number of neurons in\n",
    "# the previous layer (one input coming from each neuron). As \n",
    "# this is binary classification with a single output, the number \n",
    "# of neurons equals 1. \n",
    "\n",
    "\n",
    "# Layer 0 is input layer so W0 is identity matrix while B0 is zero matrix.\n",
    "# Layer 0 in a way simply reproduces its inputs at the output\n",
    "B0 = np.zeros((NL0, 1))\n",
    "W0 = np.identity((NL0))\n",
    "\n",
    "# Layer 1 is a passthrough layer. As number of inputs to the layer equals\n",
    "# 2 and number of neurons are 4, the size of W1 will be 4 x2. To make this\n",
    "# layer a passthrough layer, the 4 x 2 W1 matrix needs to consist of a \n",
    "# a 2 x 2 identity matrix and a 2 x 2 zero matrix. Also B1 is a zero matrix\n",
    "B1 = np.zeros((NL1,1))\n",
    "W1 = np.array([[1, 0],[0, 1],[0, 0],[0, 0]])\n",
    "\n",
    "\n",
    "# Layer 2 is a simple Logistic Regression Unit. W2 and B2 are intialized as ones.\n",
    "B2 = np.ones((NL2,1))\n",
    "W2 = np.ones((NL2,IL2))\n",
    "\n",
    "# We now runs a loop for performing forward- and backpropagation\n",
    "for g in range(h):\n",
    "    # Forward propagation \n",
    "    X0 = X\n",
    "    G0 = np.matmul(W0,X0) + B0\n",
    "    H0 = unit_activation(G0)\n",
    "    X1 = H0\n",
    "    G1 = np.matmul(W1,X1) + B1\n",
    "    H1 = tanh_activation(G1)\n",
    "    X2 = H1\n",
    "    G2 = np.matmul(W2,X2) + B2\n",
    "    H2 = sigmoid_activation(G2)\n",
    "    Yhat = H2\n",
    "\n",
    "    # Determine Cost\n",
    "    J[0,g] = cost(Y, Yhat)/m\n",
    "    if (g+1) % 100 == 0:\n",
    "        cost_sample.append(J[0,g])\n",
    "    \n",
    "    # Backpropagation for layer 2\n",
    "    dJdG2 = Yhat - Y\n",
    "    dJdB2 =  np.sum(dJdG2, axis=1,keepdims=True)/m \n",
    "    dJdW2 = np.matmul(dJdG2, X2.T)/m\n",
    "    B2 = B2 - alpha * dJdB2\n",
    "    W2 = W2 - alpha * dJdW2\n",
    "    \n",
    "    # Backpropagation for layer 1\n",
    "    dG1dW1 = np.multiply(np.matmul(W2.T, dJdG2), tanh_derivative(H1))\n",
    "    dJdB1 = np.sum(dG1dW1)/m\n",
    "    dJdW1 = np.matmul(dG1dW1, X1.T)/m\n",
    "    B1 = B1 - alpha * dJdB1\n",
    "    W1 = W1 - alpha * dJdW1\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the change in cost function against all 1000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(J[0, 0:h-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the determined model parameters to predict the output for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now run forward propagation using the Weights and Biases created by training\n",
    "\n",
    "# Using the Testing data as input -- Xt\n",
    "X0 = Xt\n",
    "G0 = np.matmul(W0,X0) + B0\n",
    "H0 = unit_activation(G0)\n",
    "X1 = H0\n",
    "G1 = np.matmul(W1,X1) + B1\n",
    "H1 = tanh_activation(G1)\n",
    "X2 = H1\n",
    "G2 = np.matmul(W2,X2) + B2\n",
    "H2 = sigmoid_activation(G2)\n",
    "Yhat = H2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the predicted output and actual output for the test data and determine percent acccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Round the Yhat values to 1 or 0\n",
    "Yt_hat = np.rint(Yhat)\n",
    "\n",
    "# Compare the Yhat values to the Yt values for the test data\n",
    "Yt_compare = np.equal(Yt, Yt_hat)\n",
    "\n",
    "# Compute percent accuracy\n",
    "Yt_accuracy = np.mean(Yt_compare)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost_sample list is:\n",
      " [0.5546217217789945, 0.512046462964825, 0.4730618707030798, 0.4417617088901453, 0.4195251292743684, 0.4035082021866837, 0.3914011936360476, 0.38186108639530936, 0.37410667824934885, 0.36765582926211254]\n",
      "\n",
      "\n",
      "The accuracy is: 80.0%\n",
      "\n",
      "\n",
      "W1:\n",
      " [[ 1.25069304 -1.36991328]\n",
      " [ 0.02705851  1.79566111]\n",
      " [-0.82429883 -0.80958968]\n",
      " [-0.82429883 -0.80958968]]\n",
      "B1:\n",
      " [[-0.01422029]\n",
      " [-0.01422029]\n",
      " [-0.01422029]\n",
      " [-0.01422029]]\n",
      "W2:\n",
      " [[2.32248823 2.59015526 1.19082565 1.19082565]]\n",
      "B2:\n",
      " [[-0.00581167]]\n"
     ]
    }
   ],
   "source": [
    "# Print the cost sample\n",
    "print(\"The cost_sample list is:\\n\", cost_sample)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print out the accuracy using the mean of True/False values\n",
    "print(\"The accuracy is: {}%\".format(Yt_accuracy))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the model parameters\n",
    "print(\"W1:\\n\", W1)\n",
    "print(\"B1:\\n\", B1)\n",
    "print(\"W2:\\n\", W2)\n",
    "print(\"B2:\\n\", B2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
