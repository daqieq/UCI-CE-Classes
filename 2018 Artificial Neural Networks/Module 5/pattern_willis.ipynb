{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the Artificial Neural Network to Logistic Regression for Pattern Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the ANN by splitting the CSV dataset and using a single Logistic Regression layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Weights array after training is: [[ 0.08056186  1.         -0.24098445  1.        ]]\n",
      "The Biases array after training is: [[-0.00078901]]\n",
      "The last value of the Cost Function is: 0.6636268397341353\n",
      "The percentage accuracy from 320 training examples and 80 testing examples is: 45.0%\n"
     ]
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Unity/Identity activation function for layer 0\n",
    "def identity_activation(G0):\n",
    "    return G0\n",
    "\n",
    "# TanH activation function for layer 1\n",
    "def tanh_activation(G1):\n",
    "    return (np.exp(G1)-np.exp(-G1))/(np.exp(G1)+np.exp(-G1))\n",
    "\n",
    "# Sigmoid activation function for layer 2\n",
    "def sigmoid_activation(G2):\n",
    "    return 1/(1+np.exp(-G2))\n",
    "\n",
    "# Initialize Weights and Biases\n",
    "def initialize_weights_and_biases(n):\n",
    "    W0 = np.identity(n)\n",
    "    b0 = np.zeros((n,1))\n",
    "    \n",
    "    # Replaced identity matrix with a matrix that reproduces two of four outputs exactly as inputs and the other two as zeros\n",
    "    W1 = np.array([[1,0],[0,0],[0,1],[0,0]])\n",
    "    b1 = np.zeros((2*n,1))\n",
    "    \n",
    "    W2 = np.ones((1,2*n))\n",
    "    b2 = np.ones((1,1))\n",
    "    \n",
    "    return W0, b0, W1, b1, W2, b2\n",
    "\n",
    "# Cost function\n",
    "def cost_function(Y, Yhat, m):\n",
    "    return -(1/m)*np.sum(Y*np.log(Yhat) + (1-Y)*np.log(1-Yhat))\n",
    "\n",
    "def ann_logit(filename, n_train, n_features):\n",
    "    \n",
    "    # Read CSV data from input file\n",
    "    file_csv = np.genfromtxt (filename, delimiter=\",\")\n",
    "\n",
    "    # Get the Training datasets\n",
    "    X_train = file_csv[1:n_train+1,0:n_features].transpose()\n",
    "    Y_train = file_csv[1:n_train+1,n_features:n_features+1].transpose()\n",
    "\n",
    "    # Get the Testing datasets\n",
    "    X_test = file_csv[n_train+1:,0:n_features].transpose()\n",
    "    Y_test = file_csv[n_train+1:,n_features:n_features+1].transpose()\n",
    "\n",
    "    # Number of training examples\n",
    "    m = X_train.shape[1]\n",
    "\n",
    "    # Number of training features\n",
    "    n = X_train.shape[0]\n",
    "\n",
    "    # Iterations\n",
    "    h = 100000\n",
    "\n",
    "    # Learning rate\n",
    "    alpha = 0.05\n",
    "\n",
    "    # Initialize the Weights and Biases\n",
    "    W0, b0, W1, b1, W2, b2 = initialize_weights_and_biases(n)\n",
    "\n",
    "    # Initialize the J cost function array\n",
    "    J = np.zeros((1,h))\n",
    "\n",
    "    # Loop through the forward and backward steps\n",
    "    for g in range(h):\n",
    "\n",
    "        # Forward Propagation through the layers 0, 1 and 2\n",
    "        # Layer 0 - Unity\n",
    "        X1 = identity_activation(W0@X_train + b0)\n",
    "\n",
    "        # Layer 1 - Unity\n",
    "        X2 = identity_activation(W1@X1 + b1)\n",
    "\n",
    "        # Layer 2 - Sigmoid\n",
    "        Yhat = sigmoid_activation(W2@X2 + b2)\n",
    "\n",
    "        # Calculate the Cost Function\n",
    "        J[0][g] = cost_function(Y_train, Yhat, m)\n",
    "\n",
    "        # Use derivatives of J cost funtion to update the Weights and Biases\n",
    "        dJdz = Yhat - Y_train\n",
    "        dJdb = (1/m)*np.sum(dJdz)\n",
    "        dJdw = (1/m)*dJdz@np.transpose(X2)\n",
    "        b2 = b2 - alpha*dJdb\n",
    "        W2 = W2 - alpha*dJdw\n",
    "\n",
    "    print(\"The Weights array after training is: {}\".format(W2))\n",
    "    print(\"The Biases array after training is: {}\".format(b2))\n",
    "    print(\"The last value of the Cost Function is: {}\".format(J[0][h-1]))\n",
    "\n",
    "    ## Test the parms with the testing data\n",
    "    # Apply the model parameters derived during training with the sigmoid function in the activation routine\n",
    "    # Forward Propagation through the layers 0, 1 and 2\n",
    "    # Layer 0 - Unity\n",
    "    X1 = identity_activation(W0@X_test + b0)\n",
    "\n",
    "    # Layer 1 - Unity\n",
    "    X2 = identity_activation(W1@X1 + b1)\n",
    "\n",
    "    # Layer 2 - Sigmoid\n",
    "    Yhat = sigmoid_activation(W2@X2 + b2)\n",
    "    \n",
    "    # Round the Yhat values to 1 or 0\n",
    "    Yhat_test = np.rint(Yhat)\n",
    "\n",
    "    # Compare the Yhat values to the Y values from the Testing data\n",
    "    Ycomp_test = np.equal(Y_test,Yhat_test)\n",
    "    \n",
    "    # Print out the accuracy using the mean of True/False values\n",
    "    print(\"The percentage accuracy from 320 training examples and 80 testing examples is: {}%\".format(np.mean(Ycomp_test)*100))\n",
    "    \n",
    "# Call the ANN logitistic regression for the training data set\n",
    "# Pass parms:: filename, number of examples to use for training, number of X features in the data\n",
    "ann_logit('pattern_rand.csv', 320, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Weights array after training is: [[ 0.08056186  1.         -0.24098445  1.        ]]\n",
    "\n",
    "The Biases array after training is: [[-0.00078901]]\n",
    "\n",
    "The last value of the Cost Function is: 0.6636268397341353\n",
    "\n",
    "The percentage accuracy from 320 training examples and 80 testing examples is: 45.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
