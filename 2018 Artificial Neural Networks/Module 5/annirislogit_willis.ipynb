{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on Iris Data Set Using the Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ANN logistic regression on the Iris Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Weights array after training is: [[-1.37203655 -3.55865762  5.82179189  3.3445902 ]]\n",
      "The Biases array after training is: [[0.08939374]]\n",
      "The last value of the Cost Function is: 0.00023010959719113575\n"
     ]
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Unity/Identity activation function for layer 0\n",
    "def identity_activation(G0):\n",
    "    return G0\n",
    "\n",
    "# TanH activation function for layer 1\n",
    "def tanh_activation(G1):\n",
    "    return (np.exp(G1)-np.exp(-G1))/(np.exp(G1)+np.exp(-G1))\n",
    "\n",
    "# Sigmoid activation function for layer 2\n",
    "def sigmoid_activation(G2):\n",
    "    return 1/(1+np.exp(-G2))\n",
    "\n",
    "# Initialize Weights and Biases\n",
    "def initialize_weights_and_biases(n):\n",
    "    W0 = np.identity(n)\n",
    "    b0 = np.zeros((n,1))\n",
    "    \n",
    "    W1 = np.identity(n)\n",
    "    b1 = np.zeros((n,1))\n",
    "    \n",
    "    W2 = np.ones((1,n))\n",
    "    b2 = np.ones((1,1))\n",
    "    \n",
    "    return W0, b0, W1, b1, W2, b2\n",
    "\n",
    "# Cost function\n",
    "def cost_function(Y, Yhat, m):\n",
    "    return -(1/m)*np.sum(Y*np.log(Yhat) + (1-Y)*np.log(1-Yhat))\n",
    "\n",
    "def ann_logit(filename):\n",
    "    \n",
    "    # Read CSV data from input file\n",
    "    file_csv = np.genfromtxt (filename, delimiter=\",\")\n",
    "\n",
    "    X = file_csv[1:,0:4].transpose()\n",
    "    Y = file_csv[1:,4:5].transpose()\n",
    "\n",
    "    # Number of training examples\n",
    "    m = X.shape[1]\n",
    "\n",
    "    # Number of features\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # Iterations\n",
    "    h = 100000\n",
    "\n",
    "    # Learning rate\n",
    "    alpha = 0.05\n",
    "\n",
    "    # Initialize the Weights and Biases\n",
    "    W0, b0, W1, b1, W2, b2 = initialize_weights_and_biases(n)\n",
    "\n",
    "    # Initialize the J cost function array\n",
    "    J = np.zeros((1,h))\n",
    "\n",
    "    # Loop through the forward and backward steps\n",
    "    for g in range(h):\n",
    "\n",
    "        # Forward Propagation through the layers 0, 1 and 2\n",
    "        # Layer 0 - Unity\n",
    "        X1 = identity_activation(W0@X + b0)\n",
    "\n",
    "        # Layer 1 - Unity\n",
    "        X2 = identity_activation(W1@X1 + b1)\n",
    "\n",
    "        # Layer 2 - Sigmoid\n",
    "        Yhat = sigmoid_activation(W2@X2 + b2)\n",
    "\n",
    "        # Calculate the Cost Function\n",
    "        J[0][g] = cost_function(Y, Yhat, m)\n",
    "\n",
    "        # Use derivatives of J cost funtion to update the Weights and Biases\n",
    "        dJdz = Yhat - Y\n",
    "        dJdb = (1/m)*np.sum(dJdz)\n",
    "        dJdw = (1/m)*dJdz@np.transpose(X2)\n",
    "        b2 = b2 - alpha*dJdb\n",
    "        W2 = W2 - alpha*dJdw\n",
    "\n",
    "    print(\"The Weights array after training is: {}\".format(W2))\n",
    "    print(\"The Biases array after training is: {}\".format(b2))\n",
    "    print(\"The last value of the Cost Function is: {}\".format(J[0][h-1]))\n",
    "\n",
    "# Call the ANN logitistic regression for the training data set\n",
    "ann_logit('iristrain-1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Weights array after training is: [[-1.37203655 -3.55865762  5.82179189  3.3445902 ]]\n",
    "\n",
    "The Biases array after training is: [[0.08939374]]\n",
    "\n",
    "The last value of the Cost Function is: 0.00023010959719113575"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ANN logistic regression on the Iris Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Weights array after training is: [[-1.5575962  -3.09156747  5.47374584  3.04684905]]\n",
      "The Biases array after training is: [[0.08493814]]\n",
      "The last value of the Cost Function is: 0.00014143460554265697\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Call the ANN logitistic regression for the testing data set\n",
    "ann_logit('iristest-1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Weights array after training is: [[-1.5575962  -3.09156747  5.47374584  3.04684905]]\n",
    "\n",
    "The Biases array after training is: [[0.08493814]]\n",
    "\n",
    "The last value of the Cost Function is: 0.00014143460554265697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
