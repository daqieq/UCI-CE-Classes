{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Assignment\n",
    "\n",
    "This notebook can be run using \"Run All\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer Resources and Compute Time\n",
    "\n",
    "From <i>systeminfo</i> command in powershell. The laptop also has an SSD used where the corpus documents are stored, so disk IO access is faster than legacy HDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS Name:                   Microsoft Windows 10 Home  \n",
    "# Processor(s):              1 Processor(s) Installed.  \n",
    "#                            [01]: Intel64 Family 6 Model 158 Stepping 9 GenuineIntel ~2808 Mhz  \n",
    "# Total Physical Memory:     16,249 MB  \n",
    "# Available Physical Memory: 9,627 MB  \n",
    "# Virtual Memory: Max Size:  18,681 MB  \n",
    "# Virtual Memory: Available: 9,427 MB  \n",
    "# Virtual Memory: In Use:    9,254 MB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using almost the full number of corpus documents (2300/2307), I was able to process in just over 13 seconds using my custom solution. The scikit-learn method only took just over 4 seconds.  \n",
    "  \n",
    "Time elapsed during Sparse Matrix creation: 13.168128 seconds  \n",
    "Time elapsed during scikit-learn Sparse Matrix creation: 4.120006 seconds  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class definition and Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlaintextCorpusReader object created successfully.\n",
      "\n",
      "Sample of TF Sparse Matrix \n",
      "   (0, 0)\t2.6094379124341005\n",
      "  (0, 1)\t1.6931471805599454\n",
      "  (0, 2)\t4.218875824868201\n",
      "  (0, 3)\t3.833213344056216\n",
      "  (0, 4)\t4.465735902799727\n",
      "  (0, 5)\t4.871201010907891\n",
      "  (0, 6)\t1.0\n",
      "  (0, 7)\t3.0794415416798357\n",
      "  (0, 8)\t4.13549421592915\n",
      "  (0, 9)\t1.0\n",
      "\n",
      "Sample of TF-IDF Sparse Matrix \n",
      "   (0, 0)\t0.9146215382538333\n",
      "  (0, 1)\t4.3730478241573545\n",
      "  (0, 2)\t0.2683777482650514\n",
      "  (0, 3)\t0.1898345072566897\n",
      "  (0, 4)\t0.07439399506963361\n",
      "  (0, 5)\t0.076499696774644\n",
      "  (0, 6)\t0.4640488357583941\n",
      "  (0, 7)\t0.3056586420608533\n",
      "  (0, 8)\t0.1400819670919766\n",
      "  (0, 9)\t1.1536720658511372\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Define the corpus location and document pattern\n",
    "corpus_root = r\"C:\\Users\\camer\\Documents\\UCI CE Courses\\I&C SCI_X426.77 Text Mining and Analytics for Machine Learning\\Module 2\\OANC-GrAF\\data\\spoken\\telephone\\switchboard\"\n",
    "file_pattern = r\".*/.*\\.txt\"\n",
    "\n",
    "# Define the number of corpus documents to read\n",
    "NUM_DOCS = 2300\n",
    "\n",
    "class W3A():\n",
    "    \"\"\"\n",
    "    A class to hold logic for Week 3 Assignment.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, root, pattern, num_docs):\n",
    "        \"\"\"\n",
    "        Initialize the corpus reader.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.pattern = pattern\n",
    "        self.num_docs = num_docs \n",
    "\n",
    "        # Set up PCR for our Switchboard corpus\n",
    "        try:\n",
    "            self.sb_pcr = PlaintextCorpusReader(corpus_root, file_pattern)\n",
    "        except OSError:\n",
    "            print(\"Likely the Corpus root directory is incorrect.\")\n",
    "        else:\n",
    "            if len(self.sb_pcr.fileids()) == 0:\n",
    "                print(\"Zero files in corpus. Check corpus path and file pattern.\")\n",
    "            else:\n",
    "                print(\"PlaintextCorpusReader object created successfully.\")\n",
    "\n",
    "    def createSparseMatrix(self):\n",
    "        \"\"\"\n",
    "        Create sparse matrix of documents and terms.\n",
    "        \"\"\"\n",
    "        indptr = [0]\n",
    "        indices = []\n",
    "        data = []\n",
    "        vocab = {}\n",
    "        \n",
    "        # Build the lists that will be used to construct the sparse matrix\n",
    "        for file in self.sb_pcr.fileids()[0:self.num_docs]:\n",
    "            for word in self.sb_pcr.words(file):\n",
    "                index = vocab.setdefault(word, len(vocab))\n",
    "                indices.append(index)\n",
    "                data.append(1)\n",
    "            indptr.append(len(indices))\n",
    "        \n",
    "        try:\n",
    "            self.csr = csr_matrix((data, indices, indptr), dtype=float)\n",
    "        except:\n",
    "            print('Sparse matrix creation failed.')\n",
    "        \n",
    "        # Get the raw count, i.e. f(t,d), by summing the duplicate entries\n",
    "        self.csr.sum_duplicates()\n",
    "\n",
    "    def createDictSumValues(self):\n",
    "        \"\"\"\n",
    "        Create a dictionary of summed values to use for lookup.\n",
    "        \"\"\"\n",
    "        dict_stack = {}\n",
    "        for j in range(len(self.csr.data)):\n",
    "\n",
    "            key = self.csr.indices[j]\n",
    "            value = self.csr.data[j]\n",
    "\n",
    "            if key in dict_stack:\n",
    "                dict_stack[key] += value\n",
    "            else:\n",
    "                dict_stack[key] = value\n",
    "                \n",
    "        return dict_stack\n",
    "    \n",
    "    \n",
    "# Record the starting time\n",
    "started = time.time()\n",
    "\n",
    "# Instantiate the Week 3 Assignment class with parameters set at the top of this code\n",
    "week3 = W3A(corpus_root, file_pattern, NUM_DOCS)\n",
    "\n",
    "# Create the sparse matrix as a attribute of the class\n",
    "# (csr_matrix did not like to return from the function, maybe I needed to copy() it)\n",
    "week3.createSparseMatrix()\n",
    "\n",
    "# Create a copy of the csr for TF and TF-IDF results\n",
    "tf_csr = week3.csr.copy()\n",
    "tf_idf_csr = week3.csr.copy()\n",
    "\n",
    "# Use the TF logic from page 63 of textbook\n",
    "tf_csr.data = 1 + np.log(tf_csr.data)\n",
    "\n",
    "# Create a dict to hold the sum of all the tokens in each document\n",
    "dict_tf_idf = week3.createDictSumValues()\n",
    "\n",
    "# Loop through the TF-IDF sparse matrix one document at a time\n",
    "for j in range(len(tf_idf_csr.data)):\n",
    "    \n",
    "    # Use the TF-IDF logic from page 63 of the textbook\n",
    "    tf_idf_csr.data[j] = tf_csr.data[j] * (np.log(1+(NUM_DOCS/dict_tf_idf[tf_idf_csr.indices[j]])))\n",
    "\n",
    "elapsed = time.time() - started\n",
    "\n",
    "# Print samples\n",
    "print(\"\\nSample of TF Sparse Matrix \\n\", tf_csr[0,0:10])\n",
    "print(\"\\nSample of TF-IDF Sparse Matrix \\n\", tf_idf_csr[0,0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed during Sparse Matrix creation: 13.168128 seconds\n"
     ]
    }
   ],
   "source": [
    "# Show the time taken to run the above process\n",
    "\n",
    "print(f\"Time elapsed during Sparse Matrix creation: {:06.6f} seconds\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Work: Create TF and TF-IDF matrices using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of sklearn TF Sparse Matrix \n",
      "   (0, 25916)\t1.0\n",
      "  (0, 3162)\t2.386294361119891\n",
      "  (0, 10358)\t1.0\n",
      "  (0, 22909)\t1.6931471805599454\n",
      "  (0, 20081)\t1.0\n",
      "  (0, 14062)\t1.0\n",
      "  (0, 3248)\t1.0\n",
      "  (0, 23274)\t1.0\n",
      "  (0, 22390)\t1.0\n",
      "  (0, 5306)\t1.0\n",
      "  (0, 10791)\t1.0\n",
      "  (0, 23632)\t1.0\n",
      "  (0, 21924)\t1.0\n",
      "  (0, 4503)\t1.0\n",
      "  (0, 8537)\t1.0\n",
      "  (0, 6320)\t1.0\n",
      "  (0, 25342)\t1.0\n",
      "  (0, 8015)\t1.0\n",
      "  (0, 12353)\t1.0\n",
      "  (0, 23593)\t1.0\n",
      "  (0, 2010)\t1.6931471805599454\n",
      "  (0, 15169)\t1.0\n",
      "  (0, 24807)\t1.0\n",
      "  (0, 6633)\t1.0\n",
      "  (0, 14351)\t1.0\n",
      "  :\t:\n",
      "  (0, 24241)\t3.8903717578961645\n",
      "  (0, 11385)\t3.8903717578961645\n",
      "  (0, 25416)\t3.0794415416798357\n",
      "  (0, 25338)\t3.3978952727983707\n",
      "  (0, 10485)\t3.302585092994046\n",
      "  (0, 15925)\t1.0\n",
      "  (0, 15619)\t3.833213344056216\n",
      "  (0, 24206)\t1.0\n",
      "  (0, 15385)\t1.6931471805599454\n",
      "  (0, 6843)\t3.0794415416798357\n",
      "  (0, 25453)\t3.4849066497880004\n",
      "  (0, 860)\t4.555348061489413\n",
      "  (0, 25750)\t2.386294361119891\n",
      "  (0, 9045)\t2.09861228866811\n",
      "  (0, 7082)\t3.1972245773362196\n",
      "  (0, 25940)\t4.367295829986475\n",
      "  (0, 11025)\t1.6931471805599454\n",
      "  (0, 89)\t1.6931471805599454\n",
      "  (0, 22907)\t1.0\n",
      "  (0, 23561)\t4.13549421592915\n",
      "  (0, 13179)\t3.0794415416798357\n",
      "  (0, 25898)\t3.833213344056216\n",
      "  (0, 24252)\t4.218875824868201\n",
      "  (0, 10685)\t1.6931471805599454\n",
      "  (0, 15669)\t2.6094379124341005\n",
      "\n",
      "Sample of sklearn TF-IDF Sparse Matrix \n",
      "   (0, 15669)\t6.337309907695799\n",
      "  (0, 10685)\t7.778137652231497\n",
      "  (0, 24252)\t25.44947494422586\n",
      "  (0, 25898)\t17.133508539594697\n",
      "  (0, 13179)\t8.115563401501786\n",
      "  (0, 23561)\t23.00999782671687\n",
      "  (0, 22907)\t2.182901287223097\n",
      "  (0, 89)\t2.063581513298994\n",
      "  (0, 11025)\t2.3956514866598395\n",
      "  (0, 25940)\t29.0\n",
      "  (0, 7082)\t41.972054815166814\n",
      "  (0, 9045)\t3.0183086880377545\n",
      "  (0, 25750)\t5.852642068358817\n",
      "  (0, 860)\t35.0\n",
      "  (0, 25453)\t12.152199722331888\n",
      "  (0, 6843)\t8.097946129462581\n",
      "  (0, 15385)\t7.3953479462322385\n",
      "  (0, 24206)\t2.0947085751876364\n",
      "  (0, 15619)\t17.0\n",
      "  (0, 15925)\t6.256192440247365\n",
      "  (0, 10485)\t10.017398873462675\n",
      "  (0, 25338)\t44.24860240614298\n",
      "  (0, 25416)\t8.034843260654963\n",
      "  (0, 11385)\t18.007824386126245\n",
      "  (0, 24241)\t18.015652174899316\n",
      "  :\t:\n",
      "  (0, 14351)\t2.086946569852147\n",
      "  (0, 6633)\t6.256192440247365\n",
      "  (0, 24807)\t1.0814561354706835\n",
      "  (0, 15169)\t1.5959029550381947\n",
      "  (0, 2010)\t2.430918229987661\n",
      "  (0, 23593)\t2.9853568764484537\n",
      "  (0, 12353)\t6.543874512699147\n",
      "  (0, 8015)\t3.0541237336955462\n",
      "  (0, 25342)\t5.522223265167165\n",
      "  (0, 6320)\t5.185751028545952\n",
      "  (0, 8537)\t1.8731246810650735\n",
      "  (0, 4503)\t3.7712857904593653\n",
      "  (0, 21924)\t3.3566040272462767\n",
      "  (0, 23632)\t1.1888618024745645\n",
      "  (0, 10791)\t2.5548904661348724\n",
      "  (0, 5306)\t4.979898974341804\n",
      "  (0, 22390)\t3.2986813795135723\n",
      "  (0, 23274)\t3.6412326622111677\n",
      "  (0, 3248)\t3.6721948878151345\n",
      "  (0, 14062)\t1.203669053448857\n",
      "  (0, 20081)\t1.341701006704012\n",
      "  (0, 22909)\t3.733801189164143\n",
      "  (0, 10358)\t3.920817524430329\n",
      "  (0, 3162)\t10.162359663970705\n",
      "  (0, 25916)\t2.85499505858521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "started = time.time()\n",
    "\n",
    "# Use the defaults except read a list of file paths instead of a list of document text entries\n",
    "vectorizer1 = CountVectorizer(input='filename')\n",
    "\n",
    "# Note - we are reusing the PCR corpus object from the W3A class\n",
    "freq_count = vectorizer1.fit_transform(week3.sb_pcr.abspaths()[0:NUM_DOCS])\n",
    "\n",
    "# Set the min value at 1 and normalize the data using a natural log function\n",
    "freq_count.data = 1 + np.log(freq_count.data)\n",
    "\n",
    "# Use the defaults except read a list of file paths instead of a list of document text entries\n",
    "vectorizer2 = TfidfVectorizer(input='filename',norm=None)\n",
    "\n",
    "# Note - we are reusing the PCR corpus object from the W3A class\n",
    "tf_idf = vectorizer2.fit_transform(week3.sb_pcr.abspaths()[0:NUM_DOCS])\n",
    "\n",
    "elapsed2 = time.time() - started\n",
    "\n",
    "# Print a (larger) sample (sklearn does not order the 2nd dimension)\n",
    "print(\"\\nSample of sklearn TF Sparse Matrix \\n\", freq_count[0])\n",
    "print(\"\\nSample of sklearn TF-IDF Sparse Matrix \\n\", tf_idf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed during scikit-learn Sparse Matrix creation: 4.120006 seconds\n"
     ]
    }
   ],
   "source": [
    "# Show the time taken to run the above process\n",
    "\n",
    "print(\"Time elapsed during scikit-learn Sparse Matrix creation: {:06.6f} seconds\".format(elapsed2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
